{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Deploy mapping pipeline\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install requirements"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install python-dotenv"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: python-dotenv in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (1.0.0)\r\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1698307976563
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Init workspace"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import dotenv_values\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "import os\n",
        "\n",
        "env_vars = dotenv_values(\"env\")\n",
        "for key, value in env_vars.items():\n",
        "     os.environ[key] = value\n",
        "subscription_id = os.getenv(\"SUBSCRIPTION_ID\")\n",
        "workspace_name = os.getenv(\"WORKSPACE_NAME\")\n",
        "version = os.getenv(\"VERSION\")\n",
        "print(f\"workspace_name={workspace_name}\")\n",
        "print(f\"version={version}\")\n",
        "\n",
        "# authenticate\n",
        "credential = DefaultAzureCredential()\n",
        "\n",
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=subscription_id,\n",
        "    resource_group_name=\"DocuBank\",\n",
        "    workspace_name=workspace_name,\n",
        ")\n",
        "cpu_cluster = None"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "workspace_name=bankmap\nversion=0.0.5\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "gather": {
          "logged": 1698307989998
        },
        "name": "ml_client"
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### Create a compute resource to run your pipeline (Optional)\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "# Name assigned to the compute cluster\n",
        "cpu_compute_target = \"cpu-cluster-lp\"\n",
        "\n",
        "try:\n",
        "    # let's see if the compute target already exists\n",
        "    cpu_cluster = ml_client.compute.get(cpu_compute_target)\n",
        "    print(\n",
        "        f\"You already have a cluster named {cpu_compute_target}, we'll reuse it as is.\"\n",
        "    )\n",
        "\n",
        "except Exception:\n",
        "    print(\"Creating a new cpu compute target...\")\n",
        "\n",
        "    # Let's create the Azure Machine Learning compute object with the intended parameters\n",
        "    # if you run into an out of quota error, change the size to a comparable VM that is available.\n",
        "    # Learn more on https://azure.microsoft.com/en-us/pricing/details/machine-learning/.\n",
        "    cpu_cluster = AmlCompute(\n",
        "        name=cpu_compute_target,\n",
        "        # Azure Machine Learning Compute is the on-demand VM service\n",
        "        type=\"amlcompute\",\n",
        "        # VM Family\n",
        "        size=\"STANDARD_DS3_V2\",\n",
        "        # Minimum running nodes when there is no job running\n",
        "        min_instances=0,\n",
        "        # Nodes in cluster\n",
        "        max_instances=20,\n",
        "        # How many seconds will the node running after the job termination\n",
        "        idle_time_before_scale_down=600,\n",
        "        # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
        "        tier=\"LowPriority\",\n",
        "    )\n",
        "    print(\n",
        "        f\"AMLCompute with name {cpu_cluster.name} will be created, with compute size {cpu_cluster.size}\"\n",
        "    )\n",
        "    # Now, we pass the object to MLClient's create_or_update method\n",
        "    cpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "You already have a cluster named cpu-cluster-lp, we'll reuse it as is.\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1698308223478
        },
        "name": "cpu_cluster"
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### Set Params"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "conda_file = \"./conda.yaml\"\n",
        "code_dir = \"./src\"\n",
        "env_name = \"bankmap\"\n",
        "component_name = \"bankmap\"\n",
        "\n",
        "config_path=f\"azureml://subscriptions/ae0eff97-7885-4c1e-b23c-d8a627ef292f/resourcegroups/DocuBank/workspaces/{workspace_name}/datastores/configs/paths/\"\n",
        "input_path=f\"azureml://subscriptions/ae0eff97-7885-4c1e-b23c-d8a627ef292f/resourcegroups/DocuBank/workspaces/{workspace_name}/datastores/datawork/paths/\""
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1698308099780
        },
        "name": "dependencies_dir"
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### Create environment\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "pipeline_job_env = Environment(\n",
        "    name=env_name,\n",
        "    description=\"Env to run map pipeline\",\n",
        "    tags={\"bankmap\": version},\n",
        "    conda_file=conda_file,\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
        "    version=version,\n",
        ")\n",
        "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
        "\n",
        "print(\n",
        "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Environment with name bankmap is registered to workspace, the environment version is 0.0.5\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "gather": {
          "logged": 1698308111646
        },
        "name": "custom_env_name"
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### Create component\n",
        "\n",
        "And register the component in the workspace for future reuse.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input, Output\n",
        "\n",
        "outputs={\"output\": Output(type=\"uri_file\", mode=\"rw_mount\")}\n",
        "map_component = command(\n",
        "    name=component_name,\n",
        "    display_name=\"Maps statement to DB for a company\",\n",
        "    description=\"Maps statement to DB for a company\",\n",
        "    inputs={\n",
        "        \"data\":  Input(type=\"uri_file\"),\n",
        "        \"config_path\":  Input(type=\"uri_folder\"),\n",
        "        \"company\": Input(type=\"string\")\n",
        "    },\n",
        "    is_deterministic=True, \n",
        "    outputs=outputs,\n",
        "    # The source folder of the component\n",
        "    code=code_dir,\n",
        "    version=version,\n",
        "    command=\"\"\"python map.py \\\n",
        "            --company '${{inputs.company}}' \\\n",
        "            --input_file '${{inputs.data}}'\\\n",
        "            --config_path '${{inputs.config_path}}'\\\n",
        "            --output '${{outputs.output}}'\\\n",
        "            \"\"\",\n",
        "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
        ")\n",
        "\n",
        "# Now we register the component to the workspace\n",
        "map_component = ml_client.create_or_update(map_component.component)\n",
        "\n",
        "# Create (register) the component in your workspace\n",
        "print(f\"Component {map_component.name} with Version {map_component.version} is registered\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\r\u001b[32mUploading src (0.0 MBs):   0%|          | 0/4200 [00:00<?, ?it/s]\r\u001b[32mUploading src (0.0 MBs): 100%|██████████| 4200/4200 [00:00<00:00, 39990.28it/s]\r\u001b[32mUploading src (0.0 MBs): 100%|██████████| 4200/4200 [00:00<00:00, 39606.89it/s]\n\u001b[39m\n\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Component bankmap with Version 0.0.5 is registered\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1698308177503
        },
        "name": "data_prep_component"
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### Optional: Test component\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# the dsl decorator tells the sdk that we are defining an Azure Machine Learning pipeline\n",
        "from azure.ai.ml import dsl, Input, Output\n",
        "\n",
        "map_component = ml_client.components.get(component_name)\n",
        "print(f'output: {map_component}')\n",
        "\n",
        "@dsl.pipeline(compute=cpu_compute_target, description=\"test map pipeline\")\n",
        "def map_pipeline(company, data, config_path):\n",
        "    job = map_component(company=company, data=data, config_path=config_path)\n",
        "    # job.outputs[\"output_path\"] = Output(type=\"uri_folder\", mode=\"rw_mount\", path=output_path)\n",
        "    print(f'output: {job.outputs[\"output\"]}')\n",
        "    return {\n",
        "        \"output\": job.outputs.output\n",
        "    }"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "output: name: bankmap\nversion: 0.0.5\ndisplay_name: Maps statement to DB for a company\ndescription: Maps statement to DB for a company\ntype: command\ninputs:\n  data:\n    type: uri_file\n    optional: false\n  config_path:\n    type: uri_folder\n    optional: false\n  company:\n    type: string\n    optional: false\noutputs:\n  output:\n    type: uri_file\ncommand: 'python map.py             --company ''${{inputs.company}}''             --input_file\n  ''${{inputs.data}}''            --config_path ''${{inputs.config_path}}''            --output\n  ''${{outputs.output}}''            '\nenvironment: azureml:/subscriptions/ae0eff97-7885-4c1e-b23c-d8a627ef292f/resourceGroups/DocuBank/providers/Microsoft.MachineLearningServices/workspaces/bankmap/environments/bankmap/versions/0.0.5\ncode: azureml:/subscriptions/ae0eff97-7885-4c1e-b23c-d8a627ef292f/resourceGroups/DocuBank/providers/Microsoft.MachineLearningServices/workspaces/bankmap/codes/9226ca34-952a-48b1-84a9-2ade8f2d942f/versions/1\nresources:\n  instance_count: 1\ncreation_context:\n  created_at: '2023-10-26T08:16:16.827138+00:00'\n  created_by: \"Airenas Vai\\u010Di\\u016Bnas\"\n  created_by_type: User\n  last_modified_at: '2023-10-26T08:16:16.903353+00:00'\n  last_modified_by: \"Airenas Vai\\u010Di\\u016Bnas\"\n  last_modified_by_type: User\nis_deterministic: true\nid: azureml:/subscriptions/ae0eff97-7885-4c1e-b23c-d8a627ef292f/resourceGroups/DocuBank/providers/Microsoft.MachineLearningServices/workspaces/bankmap/components/bankmap/labels/default\n\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "gather": {
          "logged": 1698308233912
        },
        "name": "pipeline"
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "### Run job"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's instantiate the pipeline with the parameters of our choice\n",
        "company=\"\"\n",
        "pipeline = map_pipeline(\n",
        "    company=company,\n",
        "    data=Input(type=\"uri_file\", path=f\"azureml://subscriptions/ae0eff97-7885-4c1e-b23c-d8a627ef292f/resourcegroups/DocuBank/workspaces/{workspace_name}/datastores/datacopy/paths/{company}.zip\"),\n",
        "    config_path=Input(type=\"uri_folder\", path=config_path)\n",
        ")\n",
        "\n",
        "pipeline_job = ml_client.jobs.create_or_update(\n",
        "    pipeline,\n",
        "    experiment_name=\"Test fo map deploy\",\n",
        ")\n",
        "print(f'output: {pipeline_job.outputs.output.path}')\n",
        "print(f'output: {pipeline_job.name}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "output: ${{parent.jobs.None.outputs.output}}\noutput: None\noutput: ashy_heart_ptbyrb0c3d\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "attributes": {
          "classes": [
            "Python"
          ],
          "id": ""
        },
        "gather": {
          "logged": 1698308796010
        },
        "name": "registered_model_name"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ml_client.jobs.stream(pipeline_job.name)\n",
        "retrieved_job = ml_client.jobs.get(pipeline_job.name)\n",
        "print(f'output: {retrieved_job}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "output: name: clever_neck_7w8w1hvx5s\ndisplay_name: map_pipeline\ndescription: test map pipeline\ntype: pipeline\ninputs:\n  company: hum\n  data:\n    mode: ro_mount\n    type: uri_file\n    path: azureml://subscriptions/ae0eff97-7885-4c1e-b23c-d8a627ef292f/resourcegroups/DocuBank/workspaces/test/datastores/devcopy/paths/hum.zip\n  config_path:\n    mode: ro_mount\n    type: uri_folder\n    path: azureml://subscriptions/ae0eff97-7885-4c1e-b23c-d8a627ef292f/resourcegroups/DocuBank/workspaces/test/datastores/configs/paths/\noutputs:\n  output:\n    mode: rw_mount\n    type: uri_file\njobs:\n  job:\n    type: command\n    inputs:\n      data:\n        path: ${{parent.inputs.data}}\n      config_path:\n        path: ${{parent.inputs.config_path}}\n      company:\n        path: ${{parent.inputs.company}}\n    outputs:\n      output: ${{parent.outputs.output}}\n    resources:\n      instance_count: 1\n    component: azureml:bankmap@default\nid: azureml:/subscriptions/ae0eff97-7885-4c1e-b23c-d8a627ef292f/resourceGroups/DocuBank/providers/Microsoft.MachineLearningServices/workspaces/test/jobs/clever_neck_7w8w1hvx5s\nproperties:\n  mlflow.source.git.repoURL: git@github.com:airenas/re-bankmap.git\n  mlflow.source.git.branch: main\n  mlflow.source.git.commit: af07c8db345ecaec5fdbc32a9eedd3097d478c3e\n  azureml.git.dirty: 'True'\n  azureml.DevPlatv2: 'true'\n  azureml.DatasetAccessMode: Asset\n  azureml.runsource: azureml.PipelineRun\n  runSource: MFE\n  runType: HTTP\n  azureml.parameters: '{\"company\":\"hum\"}'\n  azureml.continue_on_step_failure: 'True'\n  azureml.continue_on_failed_optional_input: 'True'\n  azureml.enforceRerun: 'False'\n  azureml.defaultComputeName: cpu-cluster-lp\n  azureml.defaultDataStoreName: workspaceblobstore\n  azureml.pipelineComponent: pipelinerun\n  azureml.pipelines.stages: '{\"Initialization\":null,\"Execution\":{\"StartTime\":\"2023-10-20T15:05:03.5776003+00:00\",\"EndTime\":\"2023-10-20T15:05:39.7647401+00:00\",\"Status\":\"Finished\"}}'\ncreation_context:\n  created_at: '2023-10-20T15:05:02.331197+00:00'\n  created_by: \"Airenas Vai\\u010Di\\u016Bnas\"\n  created_by_type: User\ncompute: azureml:cpu-cluster-lp\nservices:\n  Tracking:\n    endpoint: azureml://northeurope.api.azureml.ms/mlflow/v1.0/subscriptions/ae0eff97-7885-4c1e-b23c-d8a627ef292f/resourceGroups/DocuBank/providers/Microsoft.MachineLearningServices/workspaces/test?\n    type: Tracking\n  Studio:\n    endpoint: https://ml.azure.com/runs/clever_neck_7w8w1hvx5s?wsid=/subscriptions/ae0eff97-7885-4c1e-b23c-d8a627ef292f/resourcegroups/DocuBank/workspaces/test&tid=b2ffa4d2-017d-4706-8e9d-fdda02bf7ffc\n    type: Studio\nexperiment_name: Test_fo_map_deploy\nstatus: Completed\n\n"
        }
      ],
      "execution_count": 44,
      "metadata": {
        "gather": {
          "logged": 1697814571852
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = ml_client.jobs.download(name=pipeline_job.name, output_name=\"output\")\n",
        "print(f'output: {output}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Downloading artifact azureml://subscriptions/ae0eff97-7885-4c1e-b23c-d8a627ef292f/resourcegroups/DocuBank/workspaces/test/datastores/workspaceblobstore/paths/azureml/22943b06-74c2-4587-bc45-7e93bc21636a/output to named-outputs/output\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "output: None\n"
        }
      ],
      "execution_count": 53,
      "metadata": {
        "gather": {
          "logged": 1697815697865
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "categories": [
      "SDK v2",
      "tutorials",
      "get-started-notebooks"
    ],
    "description": {
      "description": "Create production ML pipelines with Python SDK v2 in a Jupyter notebook"
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}